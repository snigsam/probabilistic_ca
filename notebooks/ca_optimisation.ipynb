{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jax.config import config\n",
    "config.update(\"jax_debug_nans\", True)\n",
    "config.update(\"jax_enable_x64\", True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import probabilistic_ca as ca"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Target and Initial States"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(seed=101)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of steps to run the CA for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_STEPS = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use a known rule to generate target data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rule_113 = ca.rule_arr(\n",
    "    113, \n",
    "    idxs=tuple(np.arange(8)), \n",
    "    perbs=tuple(1e-6 * np.ones(8))\n",
    ")[:, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then use a random rule as a starting point for optimisation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_rule = rng.uniform(0.25, 0.75, 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And a fixed random initial state:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = rng.uniform(1e-8, 1-1e-8, (2, 100))\n",
    "random_state = np.log(ca.state_to_joint(random_state))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utility Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function converts a 1d-rule array to a joint probabilty, then run the CA with this rule:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@partial(jax.jit, static_argnames=(\"steps\",))\n",
    "def run_model(rule_arr, state, steps):\n",
    "    \n",
    "    ra = jnp.stack(\n",
    "        (rule_arr, 1.- rule_arr)\n",
    "    ).T\n",
    "    ra = jnp.log(ra)\n",
    "    \n",
    "    j = ca.rule_to_joint(ra, log_prob=True)\n",
    "    \n",
    "    return ca.run_model(j, state, steps, log_prob=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Target Output\n",
    "\n",
    "We can them generate a target output, the probability of individual states generated by rule 113:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = run_model(rule_113, random_state, N_STEPS)\n",
    "target = jnp.exp(ca.state_probabilities(target)[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.matshow(target, cmap=\"gray\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimisation Function\n",
    "\n",
    "This function then run the model and calculates the MSE between the generated series and the target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@partial(jax.jit, static_argnames=(\"steps\",))\n",
    "def diff_run(rule_arr, state, steps):\n",
    "    \n",
    "    ts = run_model(rule_arr, state, steps)\n",
    "    \n",
    "    loss = target - jnp.exp(\n",
    "        ca.state_probabilities(ts)[:, 1]\n",
    "    )\n",
    "    loss = jnp.mean(loss ** 2)\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the actual optimisation loop we use basic gradient descent on the CA rule probabilities. Since these will be converted to log probabilities we clip them inside the range ``(1e-8, 1 - 1e-8)``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@partial(\n",
    "    jax.jit, \n",
    "    static_argnames=(\"steps\", \"opt_steps\")\n",
    ")\n",
    "def opt(\n",
    "    rule, state, steps, opt_steps, epsilon=1e-4\n",
    "):\n",
    "    \n",
    "    def inner_opt(r, x):\n",
    "        \n",
    "        loss, g = jax.value_and_grad(diff_run)(r, state, steps)\n",
    "        r = r - epsilon * g\n",
    "        r = np.clip(r, 1e-8, 1 - 1e-8)\n",
    "        \n",
    "        ts = run_model(r, state, steps)\n",
    "        p = ca.state_probabilities(ts)[:, 1]\n",
    "        \n",
    "        return r, (p, loss, g, r)\n",
    "    \n",
    "    return jax.lax.scan(\n",
    "        inner_opt, rule, None, length=opt_steps\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then run the gradient descent loop for 25k steps (this may take a couple minutes based on your hardware) starting from the random initial rule."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, (probs, loss, grads, rules) = opt(\n",
    "    random_rule, random_state, N_STEPS, 25_001, epsilon=1e-2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The optimisation process does reach a ruleset very close to the target (~$\\pm 10^{-7}$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(np.arange(8), np.abs(rules[-1] - rule_113));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting the MSE over training steps we can see how the MSE improves over training, though the shape of the training curve is interesting, given how it slows until quickly improving as we close in on the target rule.\n",
    "We see this shape reflected in the gradient for each of the probabilities that make up the update rule, they are relatively flat until we reach the target rule."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "ax[0].plot(loss)\n",
    "ax[0].set_xlabel(\"Step\")\n",
    "ax[0].set_ylabel(\"MSE\")\n",
    "\n",
    "ax[1].plot(grads)\n",
    "ax[1].set_xlabel(\"Step\")\n",
    "ax[1].set_ylabel(\"Gradient\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also visualise the series generated by succesive rules over training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(7, 1, figsize=(10, 12))\n",
    "\n",
    "for i, j in enumerate(range(0, 25_001, 5_000)):\n",
    "    ax[i].matshow(jnp.exp(probs[j]), cmap=\"gray\")\n",
    "    ax[i].set_xticks([])\n",
    "    ax[i].set_yticks([])\n",
    "    ax[i].set_title(f\"{j} iterations\", loc=\"left\")\n",
    "    \n",
    "ax[-1].matshow(target, cmap=\"gray\")\n",
    "ax[-1].set_xticks([])\n",
    "ax[-1].set_yticks([])\n",
    "ax[-1].set_title(\"Target\", loc=\"left\", c=\"red\")\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
